{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     net, mean, std = train()\n",
    "#     submit(net, mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import datetime\n",
    "import csv\n",
    "from lasagne.layers import InputLayer, DropoutLayer, DenseLayer\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from lasagne.objectives import binary_crossentropy\n",
    "from nolearn.lasagne import NeuralNet\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "from theano.tensor.nnet import sigmoid\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "species_map = {'CULEX RESTUANS' : \"100000\",\n",
    "              'CULEX TERRITANS' : \"010000\", \n",
    "              'CULEX PIPIENS'   : \"001000\", \n",
    "              'CULEX PIPIENS/RESTUANS' : \"101000\", \n",
    "              'CULEX ERRATICUS' : \"000100\", \n",
    "              'CULEX SALINARIUS': \"000010\", \n",
    "              'CULEX TARSALIS' :  \"000001\",\n",
    "              'UNSPECIFIED CULEX': \"001100\"} # hack!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def date(text):\n",
    "    return datetime.datetime.strptime(text, \"%Y-%m-%d\").date()\n",
    "    \n",
    "def precip(text):\n",
    "    TRACE = 1e-3\n",
    "    text = text.strip()\n",
    "    if text == \"M\":\n",
    "        return None\n",
    "    if text == \"-\":\n",
    "        return None\n",
    "    if text == \"T\":\n",
    "        return TRACE\n",
    "    return float(text)\n",
    "    \n",
    "def ll(text):\n",
    "     return int(float(text)*100)/100\n",
    "\n",
    "def impute_missing_weather_station_values(weather):\n",
    "    # Stupid simple\n",
    "    for k, v in weather.items():\n",
    "        if v[0] is None:\n",
    "            v[0] = v[1]\n",
    "        elif v[1] is None:\n",
    "            v[1] = v[0]\n",
    "        for k1 in v[0]:\n",
    "            if v[0][k1] is None:\n",
    "                v[0][k1] = v[1][k1]\n",
    "        for k1 in v[1]:\n",
    "            if v[1][k1] is None:\n",
    "                v[1][k1] = v[0][k1]\n",
    "    \n",
    "def load_weather():\n",
    "    weather = {}\n",
    "    for line in csv.DictReader(open(\"weather.csv\")):\n",
    "        for name, converter in {\"Date\" : date,\n",
    "                                \"Tmax\" : float,\"Tmin\" : float,\"Tavg\" : float,\n",
    "                                \"DewPoint\" : float, \"WetBulb\" : float,\n",
    "                                \"PrecipTotal\" : precip,\"Sunrise\" : precip,\"Sunset\" : precip,\n",
    "                                \"Depart\" : float, \"Heat\" : precip,\"Cool\" : precip,\n",
    "                                \"ResultSpeed\" : float,\"ResultDir\" : float,\"AvgSpeed\" : float,\n",
    "                                \"StnPressure\" : float, \"SeaLevel\" : float}.items():\n",
    "            x = line[name].strip()\n",
    "            line[name] = converter(x) if (x != \"M\") else None\n",
    "        station = int(line[\"Station\"]) - 1\n",
    "        assert station in [0,1]\n",
    "        dt = line[\"Date\"]\n",
    "        if dt not in weather:\n",
    "            weather[dt] = [None, None]\n",
    "        assert weather[dt][station] is None, \"duplicate weather reading {0}:{1}\".format(dt, station)\n",
    "        weather[dt][station] = line\n",
    "    impute_missing_weather_station_values(weather)        \n",
    "    return weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_training():\n",
    "    training = []\n",
    "    for line in csv.DictReader(open(\"train.csv\")):\n",
    "        for name, converter in {\"Date\" : date, \n",
    "                                \"Latitude\" : ll, \"Longitude\" : ll,\n",
    "                                \"NumMosquitos\" : int, \"WnvPresent\" : int}.items():\n",
    "            line[name] = converter(line[name])\n",
    "        training.append(line)\n",
    "    return training\n",
    "    \n",
    "def load_testing():\n",
    "    training = []\n",
    "    for line in csv.DictReader(open(\"test.csv\")):\n",
    "        for name, converter in {\"Date\" : date, \n",
    "                                \"Latitude\" : ll, \"Longitude\" : ll}.items():\n",
    "            line[name] = converter(line[name])\n",
    "        training.append(line)\n",
    "    return training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def closest_station(lat, longi):\n",
    "    # Chicago is small enough that we can treat coordinates as rectangular.\n",
    "    stations = np.array([[41.995, -87.933],\n",
    "                         [41.786, -87.752]])\n",
    "    loc = np.array([lat, longi])\n",
    "    deltas = stations - loc[None, :]\n",
    "    dist2 = (deltas**2).sum(1)\n",
    "    return np.argmin(dist2)\n",
    "       \n",
    "def normalize(X, mean=None, std=None):\n",
    "    count = X.shape[1]\n",
    "    if mean is None:\n",
    "        mean = np.nanmean(X, axis=0)\n",
    "    for i in range(count):\n",
    "        X[np.isnan(X[:,i]), i] = mean[i]\n",
    "    if std is None:\n",
    "        std = np.std(X, axis=0)\n",
    "    for i in range(count):\n",
    "        X[:,i] = (X[:,i] - mean[i]) / std[i]\n",
    "    return mean, std\n",
    "    \n",
    "def scaled_count(record):\n",
    "    SCALE = 10.0\n",
    "    if \"NumMosquitos\" not in record:\n",
    "        # This is test data\n",
    "        return 1\n",
    "    return int(np.ceil(record[\"NumMosquitos\"] / SCALE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assemble_X(base, weather):\n",
    "    X = []\n",
    "    for b in base:\n",
    "        date = b[\"Date\"]\n",
    "        lat, longi = b[\"Latitude\"], b[\"Longitude\"]\n",
    "        case = [date.year, date.month, date.day,date.weekday(), lat, longi]\n",
    "        # Look at a selection of past weather values\n",
    "        for days_ago in [1,2,3,5,8,12]:\n",
    "            day = date - datetime.timedelta(days=days_ago)\n",
    "            for obs in [\"Tmax\",\"Tmin\",\"Tavg\",\"DewPoint\",\"WetBulb\",\"PrecipTotal\",\"Depart\",\"Sunrise\",\"Sunset\",\"Heat\",\"Cool\",\"ResultSpeed\",\"ResultDir\"]:\n",
    "                station = closest_station(lat, longi)\n",
    "                case.append(weather[day][station][obs])\n",
    "        # Specify which mosquitos are present\n",
    "        species_vector = [float(x) for x in species_map[b[\"Species\"]]]\n",
    "        case.extend(species_vector)\n",
    "        # Weight each observation by the number of mosquitos seen. Test data\n",
    "        # Doesn't have this column, so in that case use 1. This accidentally\n",
    "        # Takes into account multiple entries that result from >50 mosquitos\n",
    "        # on one day. \n",
    "        for repeat in range(scaled_count(b)):\n",
    "            X.append(case)    \n",
    "    X = np.asarray(X, dtype=np.float32)\n",
    "    return X\n",
    "    \n",
    "def assemble_y(base):\n",
    "    y = []\n",
    "    for b in base:\n",
    "        present = b[\"WnvPresent\"]\n",
    "        for repeat in range(scaled_count(b)):\n",
    "            y.append(present)    \n",
    "    return np.asarray(y, dtype=np.int32).reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AdjustVariable(object):\n",
    "    def __init__(self, variable, target, half_life=20):\n",
    "        self.variable = variable\n",
    "        self.target = target\n",
    "        self.half_life = half_life\n",
    "    def __call__(self, nn, train_history):\n",
    "        delta = self.variable.get_value() - self.target\n",
    "        delta /= 2**(1.0/self.half_life)\n",
    "        self.variable.set_value(np.float32(self.target + delta))\n",
    "\n",
    "def train():\n",
    "#    weather = load_weather()\n",
    "#    training = load_training()\n",
    "    \n",
    "    X = assemble_X(training, weather)\n",
    "    mean, std = normalize(X)\n",
    "    y = assemble_y(training)\n",
    "        \n",
    "    input_size = len(X[0])\n",
    "    \n",
    "    learning_rate = theano.shared(np.float32(0.1))\n",
    "    \n",
    "    net = NeuralNet(\n",
    "    layers=[  \n",
    "        ('input', InputLayer),\n",
    "        ('hidden1', DenseLayer),\n",
    "        ('dropout1', DropoutLayer),\n",
    "        ('hidden2', DenseLayer),\n",
    "        ('dropout2', DropoutLayer),\n",
    "       # ('hidden3', DenseLayer),\n",
    "        #('dropout3', DropoutLayer),\n",
    "        ('output', DenseLayer),\n",
    "        ],\n",
    "    # layer parameters:\n",
    "    input_shape=(None, input_size), \n",
    "    hidden1_num_units=400, \n",
    "    dropout1_p=0.35,\n",
    "    hidden2_num_units=200, \n",
    "    dropout2_p=0.40,\n",
    "    #hidden3_num_units=200, \n",
    "    #dropout3_p=0.4,\n",
    "    output_nonlinearity=sigmoid, \n",
    "    output_num_units=1, \n",
    "\n",
    "    # optimization method:\n",
    "    update=nesterov_momentum,\n",
    "    update_learning_rate=learning_rate,\n",
    "    update_momentum=0.9,\n",
    "    \n",
    "    # Decay the learning rate\n",
    "    on_epoch_finished=[\n",
    "            AdjustVariable(learning_rate, target=0, half_life=2),\n",
    "            ],\n",
    "\n",
    "    # This is silly, but we don't want a stratified K-Fold here\n",
    "    # To compensate we need to pass in the y_tensor_type and the loss.\n",
    "    regression=True,\n",
    "    y_tensor_type = T.imatrix,\n",
    "    objective_loss_function = binary_crossentropy,\n",
    "     \n",
    "    max_epochs=90, \n",
    "    eval_size=0.1,\n",
    "    verbose=1,\n",
    "    )\n",
    "\n",
    "    X, y = shuffle(X, y, random_state=123)\n",
    "    net.fit(X, y)\n",
    "    \n",
    "    _, X_valid, _, y_valid = net.train_test_split(X, y, net.eval_size)\n",
    "    probas = net.predict_proba(X_valid)[:,0]\n",
    "    print(\"ROC score\", metrics.roc_auc_score(y_valid, probas))\n",
    "\n",
    "    return net, mean, std "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def submit(net, mean, std):\n",
    "    weather = load_weather()\n",
    "    testing = load_testing()\n",
    "    X = assemble_X(testing, weather) \n",
    "    normalize(X, mean, std)\n",
    "    predictions = net.predict_proba(X)[:,0]    \n",
    "    #\n",
    "    out = csv.writer(open(\"submission_final_opt_v2.csv\", \"w\"))\n",
    "    out.writerow([\"Id\",\"WnvPresent\"])\n",
    "    for row, p in zip(testing, predictions):\n",
    "        out.writerow([row[\"Id\"], p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather = load_weather()\n",
    "training = load_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = assemble_X(training, weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10506,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Address': '4100 North Oak Park Avenue, Chicago, IL 60634, USA',\n",
       "  'AddressAccuracy': '9',\n",
       "  'AddressNumberAndStreet': '4100  N OAK PARK AVE, Chicago, IL',\n",
       "  'Block': '41',\n",
       "  'Date': datetime.date(2007, 5, 29),\n",
       "  'Latitude': 41,\n",
       "  'Longitude': -88,\n",
       "  'NumMosquitos': 1,\n",
       "  'Species': 'CULEX PIPIENS/RESTUANS',\n",
       "  'Street': ' N OAK PARK AVE',\n",
       "  'Trap': 'T002',\n",
       "  'WnvPresent': 0},\n",
       " {'Address': '4100 North Oak Park Avenue, Chicago, IL 60634, USA',\n",
       "  'AddressAccuracy': '9',\n",
       "  'AddressNumberAndStreet': '4100  N OAK PARK AVE, Chicago, IL',\n",
       "  'Block': '41',\n",
       "  'Date': datetime.date(2007, 5, 29),\n",
       "  'Latitude': 41,\n",
       "  'Longitude': -88,\n",
       "  'NumMosquitos': 1,\n",
       "  'Species': 'CULEX RESTUANS',\n",
       "  'Street': ' N OAK PARK AVE',\n",
       "  'Trap': 'T002',\n",
       "  'WnvPresent': 0}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-b7368706e911>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-f48d3a16872a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m     )\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m123\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/paulperry/anaconda/lib/python2.7/site-packages/sklearn/utils/__init__.pyc\u001b[0m in \u001b[0;36mshuffle\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \"\"\"\n\u001b[1;32m    318\u001b[0m     \u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'replace'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/paulperry/anaconda/lib/python2.7/site-packages/sklearn/utils/__init__.pyc\u001b[0m in \u001b[0;36mresample\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m    236\u001b[0m             max_n_samples, n_samples))\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/paulperry/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_arrays\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m    281\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m                     \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/paulperry/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     41\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     42\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 43\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "net, mean, std = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c06d9db13799>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtesting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_testing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massemble_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweather\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mean' is not defined"
     ]
    }
   ],
   "source": [
    "weather = load_weather()\n",
    "testing = load_testing()\n",
    "X = assemble_X(testing, weather) \n",
    "normalize(X, mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = net.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
