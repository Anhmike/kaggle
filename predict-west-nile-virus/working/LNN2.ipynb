{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import datetime\n",
    "import csv\n",
    "from lasagne.layers import InputLayer, DropoutLayer, DenseLayer\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from lasagne.objectives import binary_crossentropy\n",
    "from nolearn.lasagne import NeuralNet\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "from theano.tensor.nnet import sigmoid\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "species_map = {'CULEX RESTUANS' : \"100000\",\n",
    "              'CULEX TERRITANS' : \"010000\", \n",
    "              'CULEX PIPIENS'   : \"001000\", \n",
    "              'CULEX PIPIENS/RESTUANS' : \"101000\", \n",
    "              'CULEX ERRATICUS' : \"000100\", \n",
    "              'CULEX SALINARIUS': \"000010\", \n",
    "              'CULEX TARSALIS' :  \"000001\",\n",
    "              'UNSPECIFIED CULEX': \"001100\"} # hack!\n",
    "\n",
    "def date(text):\n",
    "    return datetime.datetime.strptime(text, \"%Y-%m-%d\").date()\n",
    "    \n",
    "def precip(text):\n",
    "    TRACE = 1e-3\n",
    "    text = text.strip()\n",
    "    if text == \"M\":\n",
    "        return None\n",
    "    if text == \"-\":\n",
    "        return None\n",
    "    if text == \"T\":\n",
    "        return TRACE\n",
    "    return float(text)\n",
    "    \n",
    "def ll(text):\n",
    "     return int(float(text)*100)/100\n",
    "\n",
    "def impute_missing_weather_station_values(weather):\n",
    "    # Stupid simple\n",
    "    for k, v in weather.items():\n",
    "        if v[0] is None:\n",
    "            v[0] = v[1]\n",
    "        elif v[1] is None:\n",
    "            v[1] = v[0]\n",
    "        for k1 in v[0]:\n",
    "            if v[0][k1] is None:\n",
    "                v[0][k1] = v[1][k1]\n",
    "        for k1 in v[1]:\n",
    "            if v[1][k1] is None:\n",
    "                v[1][k1] = v[0][k1]\n",
    "    \n",
    "def load_weather():\n",
    "    weather = {}\n",
    "    for line in csv.DictReader(open(\"weather.csv\")):\n",
    "        for name, converter in {\"Date\" : date,\n",
    "                                \"Tmax\" : float,\"Tmin\" : float,\"Tavg\" : float,\n",
    "                                \"DewPoint\" : float, \"WetBulb\" : float,\n",
    "                                \"PrecipTotal\" : precip,\"Sunrise\" : precip,\"Sunset\" : precip,\n",
    "                                \"Depart\" : float, \"Heat\" : precip,\"Cool\" : precip,\n",
    "                                \"ResultSpeed\" : float,\"ResultDir\" : float,\"AvgSpeed\" : float,\n",
    "                                \"StnPressure\" : float, \"SeaLevel\" : float}.items():\n",
    "            x = line[name].strip()\n",
    "            line[name] = converter(x) if (x != \"M\") else None\n",
    "        station = int(line[\"Station\"]) - 1\n",
    "        assert station in [0,1]\n",
    "        dt = line[\"Date\"]\n",
    "        if dt not in weather:\n",
    "            weather[dt] = [None, None]\n",
    "        assert weather[dt][station] is None, \"duplicate weather reading {0}:{1}\".format(dt, station)\n",
    "        weather[dt][station] = line\n",
    "    impute_missing_weather_station_values(weather)        \n",
    "    return weather\n",
    "    \n",
    "    \n",
    "def load_training():\n",
    "    training = []\n",
    "    for line in csv.DictReader(open(\"train.csv\")):\n",
    "        for name, converter in {\"Date\" : date, \n",
    "                                \"Latitude\" : ll, \"Longitude\" : ll,\n",
    "                                \"NumMosquitos\" : int, \"WnvPresent\" : int}.items():\n",
    "            line[name] = converter(line[name])\n",
    "        training.append(line)\n",
    "    return training\n",
    "    \n",
    "def load_testing():\n",
    "    training = []\n",
    "    for line in csv.DictReader(open(\"test.csv\")):\n",
    "        for name, converter in {\"Date\" : date, \n",
    "                                \"Latitude\" : ll, \"Longitude\" : ll}.items():\n",
    "            line[name] = converter(line[name])\n",
    "        training.append(line)\n",
    "    return training\n",
    "    \n",
    "    \n",
    "def closest_station(lat, longi):\n",
    "    # Chicago is small enough that we can treat coordinates as rectangular.\n",
    "    stations = np.array([[41.995, -87.933],\n",
    "                         [41.786, -87.752]])\n",
    "    loc = np.array([lat, longi])\n",
    "    deltas = stations - loc[None, :]\n",
    "    dist2 = (deltas**2).sum(1)\n",
    "    return np.argmin(dist2)\n",
    "       \n",
    "def normalize(X, mean=None, std=None):\n",
    "    count = X.shape[1]\n",
    "    if mean is None:\n",
    "        mean = np.nanmean(X, axis=0)\n",
    "    for i in range(count):\n",
    "        X[np.isnan(X[:,i]), i] = mean[i]\n",
    "    if std is None:\n",
    "        std = np.std(X, axis=0)\n",
    "    for i in range(count):\n",
    "        X[:,i] = (X[:,i] - mean[i]) / std[i]\n",
    "    return mean, std\n",
    "    \n",
    "def scaled_count(record):\n",
    "    SCALE = 10.0\n",
    "    if \"NumMosquitos\" not in record:\n",
    "        # This is test data\n",
    "        return 1\n",
    "    return int(np.ceil(record[\"NumMosquitos\"] / SCALE))\n",
    "    \n",
    "    \n",
    "def assemble_X(base, weather):\n",
    "    X = []\n",
    "    for b in base:\n",
    "        date = b[\"Date\"]\n",
    "        lat, longi = b[\"Latitude\"], b[\"Longitude\"]\n",
    "        case = [date.year, date.month, date.day,date.weekday(), lat, longi]\n",
    "        # Look at a selection of past weather values\n",
    "        for days_ago in [1,2,3,5,8,12]:\n",
    "            day = date - datetime.timedelta(days=days_ago)\n",
    "            for obs in [\"Tmax\",\"Tmin\",\"Tavg\",\"DewPoint\",\"WetBulb\",\"PrecipTotal\",\"Depart\",\"Sunrise\",\"Sunset\",\"Heat\",\"Cool\",\"ResultSpeed\",\"ResultDir\"]:\n",
    "                station = closest_station(lat, longi)\n",
    "                case.append(weather[day][station][obs])\n",
    "        # Specify which mosquitos are present\n",
    "        species_vector = [float(x) for x in species_map[b[\"Species\"]]]\n",
    "        case.extend(species_vector)\n",
    "        # Weight each observation by the number of mosquitos seen. Test data\n",
    "        # Doesn't have this column, so in that case use 1. This accidentally\n",
    "        # Takes into account multiple entries that result from >50 mosquitos\n",
    "        # on one day. \n",
    "        for repeat in range(scaled_count(b)):\n",
    "            X.append(case)    \n",
    "    X = np.asarray(X, dtype=np.float32)\n",
    "    return X\n",
    "    \n",
    "def assemble_y(base):\n",
    "    y = []\n",
    "    for b in base:\n",
    "        present = b[\"WnvPresent\"]\n",
    "        for repeat in range(scaled_count(b)):\n",
    "            y.append(present)    \n",
    "    return np.asarray(y, dtype=np.int32).reshape(-1,1)\n",
    "\n",
    "\n",
    "class AdjustVariable(object):\n",
    "    def __init__(self, variable, target, half_life=20):\n",
    "        self.variable = variable\n",
    "        self.target = target\n",
    "        self.half_life = half_life\n",
    "    def __call__(self, nn, train_history):\n",
    "        delta = self.variable.get_value() - self.target\n",
    "        delta /= 2**(1.0/self.half_life)\n",
    "        self.variable.set_value(np.float32(self.target + delta))\n",
    "\n",
    "def train():\n",
    "    weather = load_weather()\n",
    "    training = load_training()\n",
    "    \n",
    "    X = assemble_X(training, weather)\n",
    "    mean, std = normalize(X)\n",
    "    y = assemble_y(training)\n",
    "        \n",
    "    input_size = len(X[0])\n",
    "    \n",
    "    learning_rate = theano.shared(np.float32(0.1))\n",
    "    \n",
    "    net = NeuralNet(\n",
    "    layers=[  \n",
    "        ('input', InputLayer),\n",
    "        ('hidden1', DenseLayer),\n",
    "        ('dropout1', DropoutLayer),\n",
    "        ('hidden2', DenseLayer),\n",
    "        ('dropout2', DropoutLayer),\n",
    "       # ('hidden3', DenseLayer),\n",
    "        #('dropout3', DropoutLayer),\n",
    "        ('output', DenseLayer),\n",
    "        ],\n",
    "    # layer parameters:\n",
    "    input_shape=(None, input_size), \n",
    "    hidden1_num_units=400, \n",
    "    dropout1_p=0.35,\n",
    "    hidden2_num_units=200, \n",
    "    dropout2_p=0.40,\n",
    "    #hidden3_num_units=200, \n",
    "    #dropout3_p=0.4,\n",
    "    output_nonlinearity=sigmoid, \n",
    "    output_num_units=1, \n",
    "\n",
    "    # optimization method:\n",
    "    update=nesterov_momentum,\n",
    "    update_learning_rate=learning_rate,\n",
    "    update_momentum=0.9,\n",
    "    \n",
    "    # Decay the learning rate\n",
    "    on_epoch_finished=[\n",
    "            AdjustVariable(learning_rate, target=0, half_life=2),\n",
    "            ],\n",
    "\n",
    "    # This is silly, but we don't want a stratified K-Fold here\n",
    "    # To compensate we need to pass in the y_tensor_type and the loss.\n",
    "    regression=True,\n",
    "    y_tensor_type = T.imatrix,\n",
    "    objective_loss_function = binary_crossentropy,\n",
    "     \n",
    "    max_epochs=90, \n",
    "    eval_size=0.1,\n",
    "    verbose=1,\n",
    "    )\n",
    "\n",
    "    X, y = shuffle(X, y, random_state=123)\n",
    "    net.fit(X, y)\n",
    "    \n",
    "    _, X_valid, _, y_valid = net.train_test_split(X, y, net.eval_size)\n",
    "    probas = net.predict_proba(X_valid)[:,0]\n",
    "    print(\"ROC score\", metrics.roc_auc_score(y_valid, probas))\n",
    "\n",
    "    return net, mean, std     \n",
    "    \n",
    "\n",
    "def submit(net, mean, std):\n",
    "    weather = load_weather()\n",
    "    testing = load_testing()\n",
    "    X = assemble_X(testing, weather) \n",
    "    normalize(X, mean, std)\n",
    "    predictions = net.predict_proba(X)[:,0]    \n",
    "    #\n",
    "    out = csv.writer(open(\"submission_final_opt_v2.csv\", \"w\"))\n",
    "    out.writerow([\"Id\",\"WnvPresent\"])\n",
    "    for row, p in zip(testing, predictions):\n",
    "        out.writerow([row[\"Id\"], p])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b7368706e911>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-a931350f03c5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    223\u001b[0m     )\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m123\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/paulperry/anaconda/lib/python2.7/site-packages/sklearn/utils/__init__.pyc\u001b[0m in \u001b[0;36mshuffle\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \"\"\"\n\u001b[1;32m    318\u001b[0m     \u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'replace'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/paulperry/anaconda/lib/python2.7/site-packages/sklearn/utils/__init__.pyc\u001b[0m in \u001b[0;36mresample\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m    236\u001b[0m             max_n_samples, n_samples))\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/paulperry/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_arrays\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m    281\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m                     \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/paulperry/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     41\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     42\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 43\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "net, mean, std = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather = load_weather()\n",
    "training = load_training()\n",
    "\n",
    "X = assemble_X(training, weather)\n",
    "mean, std = normalize(X)\n",
    "y = assemble_y(training)\n",
    "\n",
    "input_size = len(X[0])\n",
    "\n",
    "learning_rate = theano.shared(np.float32(0.1))\n",
    "\n",
    "net = NeuralNet(\n",
    "layers=[  \n",
    "    ('input', InputLayer),\n",
    "    ('hidden1', DenseLayer),\n",
    "    ('dropout1', DropoutLayer),\n",
    "    ('hidden2', DenseLayer),\n",
    "    ('dropout2', DropoutLayer),\n",
    "   # ('hidden3', DenseLayer),\n",
    "    #('dropout3', DropoutLayer),\n",
    "    ('output', DenseLayer),\n",
    "    ],\n",
    "# layer parameters:\n",
    "input_shape=(None, input_size), \n",
    "hidden1_num_units=400, \n",
    "dropout1_p=0.35,\n",
    "hidden2_num_units=200, \n",
    "dropout2_p=0.40,\n",
    "#hidden3_num_units=200, \n",
    "#dropout3_p=0.4,\n",
    "output_nonlinearity=sigmoid, \n",
    "output_num_units=1, \n",
    "\n",
    "# optimization method:\n",
    "update=nesterov_momentum,\n",
    "update_learning_rate=learning_rate,\n",
    "update_momentum=0.9,\n",
    "\n",
    "# Decay the learning rate\n",
    "on_epoch_finished=[\n",
    "        AdjustVariable(learning_rate, target=0, half_life=2),\n",
    "        ],\n",
    "\n",
    "# This is silly, but we don't want a stratified K-Fold here\n",
    "# To compensate we need to pass in the y_tensor_type and the loss.\n",
    "regression=True,\n",
    "y_tensor_type = T.imatrix,\n",
    "objective_loss_function = binary_crossentropy,\n",
    "\n",
    "max_epochs=90, \n",
    "eval_size=0.1,\n",
    "verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.92020607, -2.68842173,  1.54170346, -1.16103482, -0.19599773,\n",
       "               nan, -0.83835578, -1.73032331, -1.36126757, -1.47659671,\n",
       "       -1.37988901, -0.37747234, -0.16061775, -1.02678621,  0.68459719,\n",
       "       -0.23597726, -1.65325522, -0.30737841, -0.8968758 , -0.9001773 ,\n",
       "       -0.94889563, -1.01094198, -1.49634469, -1.42485094, -0.17594017,\n",
       "        0.29630819, -0.98346549,  0.6654703 , -0.22990556, -1.20817387,\n",
       "        0.81946433,  0.96812969, -1.48831773, -2.30906963, -2.04958892,\n",
       "       -0.62497365, -1.32445645,  0.50824332, -1.15244484, -0.96759146,\n",
       "        0.63420218,  2.82355189, -1.55089343, -1.16005898,  0.01385502,\n",
       "        0.9192965 ,  0.15323499,  0.53814042, -0.85026264, -0.28288671,\n",
       "       -0.28702137,  2.06097126, -0.88572615,  0.54130101, -0.31087664,\n",
       "        0.53479248,  2.66327953,  0.26624355, -0.25307229, -2.74585342,\n",
       "       -1.44987345, -1.12002051, -1.1661284 , -0.36692685, -0.06047477,\n",
       "       -0.76400381,  0.42388341,  0.78087062, -1.45849955,  0.15013595,\n",
       "       -0.56627643, -2.62483048, -2.94173026, -2.86421609, -3.52732968,\n",
       "       -3.47759318, -0.36514935, -1.0575825 , -0.58501005,  0.23120186,\n",
       "        5.56603336, -1.40929985,  1.64507699, -1.14461446,  0.68413556,\n",
       "       -0.11069065, -1.84638309, -0.00717774, -0.06747957, -0.01758495], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = shuffle(X, y, random_state=123)\n",
    "net.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, X_valid, _, y_valid = net.train_test_split(X, y, net.eval_size)\n",
    "probas = net.predict_proba(X_valid)[:,0]\n",
    "print(\"ROC score\", metrics.roc_auc_score(y_valid, probas))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
